{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\vgonsalv\\\\Desktop\\\\DataScience\\\\Other projects\\\\Sentiment Anaysis'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\vgonsalv\\\\Desktop\\\\DataScience\\\\Other projects\\\\Sentiment Anaysis\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\vgonsalv\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\vgonsalv\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tweepy) (1.12.0)\n",
      "Requirement already satisfied: requests>=2.11.1 in c:\\users\\vgonsalv\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tweepy) (2.22.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\vgonsalv\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in c:\\users\\vgonsalv\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tweepy) (1.7.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\vgonsalv\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\vgonsalv\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vgonsalv\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\vgonsalv\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (1.24.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\vgonsalv\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\vgonsalv\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\vgonsalv\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\vgonsalv\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'x8kmcPCIqvWsu5kDrPlMoIoop'\n",
    "consumer_secret = '0JZUpy65vjYhk8MAeEevOYgx8QaxLBHO2QW5fVUnqL4SYviTgp'\n",
    "access_token = '1239525741173358594-YGSUxoaKJvb9O8CEkyE4phHtF5Aym4'\n",
    "access_token_secret = 'Aiam6vvENXBUZgAGJ4lq33PKjqp7oCsoa225O4L2H8acz'\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api=tweepy.API(auth)\n",
    "results=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.search,q='Corona Virus').items(500):\n",
    "    results.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDataFrame(tweets):\n",
    "    Dataset=pd.DataFrame()\n",
    "    Dataset['Tweets_ID']=[tweet.id for tweet in tweets]\n",
    "    Dataset['Tweets_Text']=[tweet.text for tweet in tweets]\n",
    "    return Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets_ID</th>\n",
       "      <th>Tweets_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1239789628040736771</td>\n",
       "      <td>RT @BenjaminGJW: Everyone joking &amp;amp; memeing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1239789627629637633</td>\n",
       "      <td>RT @News18Bihar: चीन के जानलेवा कोरोना वायरस क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1239789627558379520</td>\n",
       "      <td>RT @akulifaaa: Gimana ya? org\" pada banyak tak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Tweets_ID                                        Tweets_Text\n",
       "0  1239789628040736771  RT @BenjaminGJW: Everyone joking &amp; memeing...\n",
       "1  1239789627629637633  RT @News18Bihar: चीन के जानलेवा कोरोना वायरस क...\n",
       "2  1239789627558379520  RT @akulifaaa: Gimana ya? org\" pada banyak tak..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset=toDataFrame(results)\n",
    "Dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-4f62f8dde698>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"english\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "stop=set(Stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(doc):\n",
    "    stop_free=\"\".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free=\"\".join(ch for ch in stop_free.split() if ch not in exclude)\n",
    "    num_free=\"\".join(i for i in punc_free.split() if not i.isdigit())\n",
    "    noise_free=\"\".join(i for i in num_free.split() if i not in noise_list)\n",
    "    stem_free=\"\".join([st.stem(i) for i in noise_free.split()])\n",
    "    spell_correct=\"\".join(TextBlob(i).correct() for i in stem_free.split())\n",
    "    punc_free_1=spell_correct.str.replace('[^\\w\\s]','')\n",
    "    html_parser=HTMLParser.HTMLParser()\n",
    "    punc_free_2=html_parser.unescape(punc_free_1)\n",
    "    encoded=punc_free_2.decode(\"UTF8\").encode('ascii','ignore')\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vgonsalv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      RT@BenjaminGJW:Everyonejoking&amp;memeingcoron...\n",
       "1      RT@News18Bihar:चीनकेजानलेवाकोरोनावायरसकाअसरअबभ...\n",
       "2      RT@akulifaaa:Gimanaya?org\"padabanyaktakutkenac...\n",
       "3      RT@gstttv:Paremdetercoronavírusetatuemcomigoht...\n",
       "4      RT@do_ra_dong:Indonesiatidaksiaphadapi\"outbrea...\n",
       "                             ...                        \n",
       "495    RT@Lowkey_Ibz:WhenthiswholeCoronavirusendwerea...\n",
       "496            VirusCoronaitubuatanilluminatifreemasonry\n",
       "497    पुलिसअधीक्षकचम्बाद्वाराकोरोनावायरसकेसंक्रमणसेव...\n",
       "498    Ouvirblogueirinhafalandoproseus20milseguidores...\n",
       "499    RT@jeybireyes:MACAUhanowZEROCASEofCoronaVirus....\n",
       "Name: Tweets_Text, Length: 500, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset['Tweets_Text'].apply(lambda x:\"\".join(Word(word).lemmatize() for word in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-ff92daf2db58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweets_Text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-d9b30b99acfd>\u001b[0m in \u001b[0;36mclean\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mstop_free\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mpunc_free\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mch\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_free\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mch\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnum_free\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpunc_free\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnoise_free\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnum_free\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnoise_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "clean(Dataset['Tweets_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['Tweets_Polarity']=Dataset['Tweets_Text'].apply(lambda x:TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets_ID</th>\n",
       "      <th>Tweets_Text</th>\n",
       "      <th>Tweets_Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1239789628040736771</td>\n",
       "      <td>RT @BenjaminGJW: Everyone joking &amp;amp; memeing...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1239789627629637633</td>\n",
       "      <td>RT @News18Bihar: चीन के जानलेवा कोरोना वायरस क...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1239789627558379520</td>\n",
       "      <td>RT @akulifaaa: Gimana ya? org\" pada banyak tak...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1239789626757447681</td>\n",
       "      <td>RT @gstttv: Parem de ter corona vírus e tatuem...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1239789626681786369</td>\n",
       "      <td>RT @do_ra_dong: Indonesia tidak siap hadapi \"o...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1239789626480566272</td>\n",
       "      <td>RT @Lowkey_Ibz: When this whole Corona virus e...</td>\n",
       "      <td>0.334091</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1239789626220580865</td>\n",
       "      <td>RT @AuntyJahlisa: My last two brain cells are ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1239789625868050433</td>\n",
       "      <td>RT @KALLIVAYALIL: India's Mos External affairs...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1239789624643502083</td>\n",
       "      <td>RT @lilhamiltrash: graças a deus não estou com...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1239789624584593409</td>\n",
       "      <td>RT @_SJPeace_: China built an entire Hospital ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Tweets_ID                                        Tweets_Text  \\\n",
       "0  1239789628040736771  RT @BenjaminGJW: Everyone joking &amp; memeing...   \n",
       "1  1239789627629637633  RT @News18Bihar: चीन के जानलेवा कोरोना वायरस क...   \n",
       "2  1239789627558379520  RT @akulifaaa: Gimana ya? org\" pada banyak tak...   \n",
       "3  1239789626757447681  RT @gstttv: Parem de ter corona vírus e tatuem...   \n",
       "4  1239789626681786369  RT @do_ra_dong: Indonesia tidak siap hadapi \"o...   \n",
       "5  1239789626480566272  RT @Lowkey_Ibz: When this whole Corona virus e...   \n",
       "6  1239789626220580865  RT @AuntyJahlisa: My last two brain cells are ...   \n",
       "7  1239789625868050433  RT @KALLIVAYALIL: India's Mos External affairs...   \n",
       "8  1239789624643502083  RT @lilhamiltrash: graças a deus não estou com...   \n",
       "9  1239789624584593409  RT @_SJPeace_: China built an entire Hospital ...   \n",
       "\n",
       "   Tweets_Polarity  Sentiment  \n",
       "0         0.000000      False  \n",
       "1         0.000000      False  \n",
       "2         0.000000      False  \n",
       "3         0.000000      False  \n",
       "4         0.000000      False  \n",
       "5         0.334091       True  \n",
       "6         0.000000      False  \n",
       "7         0.000000      False  \n",
       "8         0.000000      False  \n",
       "9         0.000000      False  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    " Dataset['Sentiment']=Dataset['Tweets_Polarity'].apply(lambda x:x>0)\n",
    "def calculate_sentiment(doc):\n",
    "    if doc['Tweets_Polarity']>0 : doc['Sentiment']='Positive'\n",
    "    elif doc['Tweets_Polarity']==0 : doc['Sentiment']='Neutral'\n",
    "    else : doc['Sentiment']='Negative'\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-05b5b1ae18d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalculate_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-51-03f7b70f6957>\u001b[0m in \u001b[0;36mcalculate_sentiment\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweets_Polarity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m    \u001b[1;32mif\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweets_Polarity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Positive'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m    \u001b[1;32melif\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweets_Polarity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Neutral'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m    \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Negative'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1553\u001b[0m             \u001b[1;34m\"The truth value of a {0} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m             \"Use a.empty, a.bool(), a.item(), a.any() or a.all().\".format(\n\u001b[1;32m-> 1555\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1556\u001b[0m             )\n\u001b[0;32m   1557\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "calculate_sentiment(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_val=pd.DataFrame(df.isnull().sum())\n",
    "missing_val=missing_val.reset_index()\n",
    "#Renaming Variable\n",
    "missing_val = missing_val.rename(columns = {'index':'Variable Name', 0 : 'Missing-Percentage'})\n",
    "#Calculating Missing Value Percentage\n",
    "missing_val['Missing-Percentage'] = (missing_val['Missing-Percentage']/len(df))*100\n",
    "missing_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
